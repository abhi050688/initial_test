{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import gc\n",
    "pd.options.display.max_columns=None\n",
    "import traceback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zee=\"F:\\ScoreData\\Zee TV\\Data_from_search_envn\"\n",
    "os.chdir(zee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Day 1', 'Day 2', 'Day 2.zip', 'Day 3', 'Day 3.zip', 'Day1.rar', 'Older search data', 'Show queries.xlsx', 'sony-tv-show-dus-ka-dum-Mentions.xls']\n"
     ]
    }
   ],
   "source": [
    "ldr=os.listdir()\n",
    "print(ldr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sonysab-show-saat-phero-ki-hera-pherie-Mentions.csv file done\n",
      "JIJAJICHHATPARHAIN-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 3-Mentions.csv file done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning:\n",
      "\n",
      "Columns (0,7,11,12,13,14,25,26,27,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starplus-show-kasautii-zindagi-kay 4-Mentions.csv file done\n",
      "starplus-show-kulfi-kumar-bajewala-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 5-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 2-Mentions.csv file done\n",
      "sonysab-show-shriman-shrimati-phir-se-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 8-Mentions.csv file done\n",
      "KRISHNACHALILONDON-Mentions.csv file done\n",
      "INDIA KE MAST KALANDAR-Mentions.csv file done\n"
     ]
    }
   ],
   "source": [
    "news_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "blogs_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "tumbler_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "instagram_ln=['No','Source','Link','Date(ET)','Time(ET)','Author ID','Author Name','Language','Location','Contents','HashTags','Likes','Comments','Attachments','Brand Images','Object Images','Food Images','Scene Images','Selfie','Sentiment','Themes','Classifications','Entities','Unique ID']\n",
    "twitter_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "news_pd=pd.DataFrame()\n",
    "blogs_pd=pd.DataFrame()\n",
    "tumbler_pd=pd.DataFrame()\n",
    "instagram_pd=pd.DataFrame()\n",
    "twitter_pd=pd.DataFrame()\n",
    "bad_files=list()\n",
    "k=0\n",
    "for dr in ldr:\n",
    "    while os.path.isdir(dr):\n",
    "        os.chdir(os.path.join(zee,dr))\n",
    "        lst=os.listdir()\n",
    "        for fle in lst:\n",
    "            if k>10:\n",
    "                break\n",
    "            k+=1\n",
    "            try:\n",
    "                data=pd.read_csv(fle,skiprows=13,parse_dates=[6],header=None)\n",
    "                news=data[data[1]==\"NEWS\"]\n",
    "                news=news.iloc[:,:len(news_ln)]\n",
    "                news.columns=news_ln\n",
    "                news['showname']=fle\n",
    "                news_pd=pd.concat([news_pd,news],axis=0)\n",
    "                del news\n",
    "                news=data[data[1]==\"BLOGS\"]\n",
    "                news=news.iloc[:,:len(blogs_ln)]\n",
    "                news.columns=blogs_ln\n",
    "                news['showname']=fle\n",
    "                blogs_pd=pd.concat([blogs_pd,news],axis=0)\n",
    "                del news\n",
    "                news=data[data[1]==\"TWITTER\"]\n",
    "                news=news.iloc[:,:len(twitter_ln)]\n",
    "                news.columns=twitter_ln\n",
    "                news['showname']=fle\n",
    "                twitter_pd=pd.concat([twitter_pd,news],axis=0)\n",
    "                del news\n",
    "                news=data[data[1]==\"TUMBLR\"]\n",
    "                news=news.iloc[:,:len(tumbler_ln)]\n",
    "                news.columns=tumbler_ln\n",
    "                news['showname']=fle\n",
    "                tumbler_pd=pd.concat([tumbler_pd,news],axis=0)\n",
    "                del news\n",
    "                news=data[data[1]==\"INSTAGRAM\"]\n",
    "                news=news.iloc[:,:len(instagram_ln)]\n",
    "                news.columns=instagram_ln\n",
    "                news['showname']=fle\n",
    "                instagram_pd=pd.concat([instagram_pd,news],axis=0)\n",
    "                del news\n",
    "                gc.collect()\n",
    "                print(\"{} file done\".format(fle))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                bad_files.append(fle)\n",
    "                print(\"{} issue in this file-------------------------------------------------\".format(fle))\n",
    "                continue\n",
    "    os.chdir(zee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALADDIN NAAM TOH SUNA HOGA-Mentions.csv file done\n",
      "andtvofficial-show-bitti-businesswali-Mentions.csv file done\n",
      "andtvofficial-show-high-fever-Mentions.csv file done\n",
      "BEECHWALE BAPU DEKH RAHA HAI-Mentions.csv file done\n",
      "BIGGBOSS 1-Mentions.csv file done\n",
      "BIGGBOSS 2-Mentions.csv file done\n",
      "BIGGBOSS 3-Mentions.csv file done\n",
      "BIGGBOSS 4-Mentions.csv file done\n",
      "colors-tv---show--dance-deewane-Mentions.csv file done\n",
      "colors-tv-show-dastan-e-mohabbat-Mentions.csv file done\n",
      "colorstv-show-belan-wali-bahu-Mentions.csv file done\n",
      "colorstv-show-bepannaah-Mentions.csv file done\n",
      "colorstv-show-dev-Mentions.csv file done\n",
      "colorstv-show-internet-wala-love-Mentions.csv file done\n",
      "ENTERTAINMENT KI RAAT-Mentions.csv file done\n",
      "sony-tv--show---cid-Mentions.csv file done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 20260: expected 52 fields, saw 54\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sony-tv-show-dus-ka-dum-Mentions.csv file done\n",
      "sony-tv-show-indian-idol-Mentions.csv file done\n",
      "sonytv-show-crime-patrol-Mentions.csv file done\n",
      "sonytv-show-zindagikecrossroads-Mentions.csv file done\n",
      "zee-tv---show---ishq-subhan-allah-Mentions.csv file done\n",
      "zee-tv---show---juzzbaaat-Mentions.csv file done\n",
      "zee-tv-shows-fear-files-Mentions.csv file done\n",
      "zeetv-show-aap-ke-aa-jane-se-Mentions.csv file done\n",
      "zeetv-show-did-lil-masters-Mentions.csv file done\n",
      "zeetv-shows-india-best-dramebaaz-Mentions.csv file done\n",
      "HARSHAAKHPEULLUBAITHAAHAI-Mentions.csv file done\n",
      "INDIA KE MAST KALANDAR-Mentions.csv file done\n",
      "JIJAJICHHATPARHAIN-Mentions.csv file done\n",
      "KHICHDI-Mentions.csv file done\n",
      "KRISHNACHALILONDON-Mentions.csv file done\n",
      "NAZAR-Mentions.csv file done\n",
      "sonysab-show-namune-Mentions.csv file done\n",
      "sonysab-show-saat-phero-ki-hera-pherie-Mentions.csv file done\n",
      "sonysab-show-shriman-shrimati-phir-se-Mentions.csv file done\n",
      "sonysab-show-supersister-Mentions.csv file done\n",
      "star-plus-show-danceplus-Mentions.csv file done\n",
      "star-plus-show-dil-hai-hindustani--Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 1-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 10-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 11-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 2-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 3-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 4-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 5-Mentions.csv file done\n",
      "Too many columns specified: expected 52 and found 25\n",
      "starplus-show-kasautii-zindagi-kay 6-Mentions.csv issue in this file-------------------------------------------------\n",
      "starplus-show-kasautii-zindagi-kay 7-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 8-Mentions.csv file done\n",
      "starplus-show-kasautii-zindagi-kay 9-Mentions.csv file done\n",
      "starplus-show-kulfi-kumar-bajewala-Mentions.csv file done\n",
      "starplus-show-mariam-khan-reporting-live-Mentions.csv file done\n",
      "starplus-show-qayamat-ki-raat-Mentions.csv file done\n",
      "starplus-show-sabse-smart-kaun-Mentions.csv file done\n",
      "andtv-show-perfect-pati-Mentions.csv file done\n",
      "andtvofficial-show-laal-ishq-Mentions.csv file done\n",
      "andtvofficial-show-love-me-india-Mentions.csv file done\n",
      "andtvofficial-show-mitegi-lakshmanrekha-Mentions.csv file done\n",
      "andtvofficial-show-vikram-betaal-Mentions.csv file done\n",
      "colors-tv-show-naagin-Mentions.csv file done\n",
      "colors-tv-show-rising-star-Mentions.csv file done\n",
      "colorstv-show-kasam-Mentions.csv file done\n",
      "colorstv-show-kaun-hai-Mentions.csv file done\n",
      "colorstv-show-roop-mard-ka-naya-swaroop-Mentions.csv file done\n",
      "colorstv-show-savitri-devi-college-and-hospital-Mentions.csv file done\n",
      "colorstv-show-silsila-badalte-rishton-ka-Mentions.csv file done\n",
      "sonytv-show-prithvi-vallabh-Mentions.csv file done\n",
      "sonytv-shows-yeh-pyaar-nahi-tho-kya-hai-Mentions.csv file done\n",
      "THE VOICE INDIA KIDS-Mentions.csv file done\n",
      "zeetv---show---kaleerein-Mentions.csv file done\n",
      "zeetv-show-ye-teri-galiyan-Mentions.csv file done\n",
      "zeetv-shows-maggie-kitchen-journeys-Mentions.csv file done\n",
      "zeetv-shows-sa-re-ga-ma-pa-Mentions.csv file done\n",
      "CHANDRASHEKAR-Mentions.csv file done\n",
      "COMEDY CIRCUS-Mentions.csv file done\n",
      "DetectiveDidi-Mentions.csv file done\n",
      "DIL HI TO HAI -Mentions.csv file done\n",
      "Guddan-Mentions.csv file done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 960: expected 52 fields, saw 53\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndiasGotTalent-Mentions.csv file done\n",
      "JIO DHAN DHANA DHAN LIVE-Mentions.csv file done\n",
      "KAUN BANEGA CROREPATI 1-Mentions.csv file done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2774: expected 52 fields, saw 53\\nSkipping line 4188: expected 52 fields, saw 53\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAUN BANEGA CROREPATI 2-Mentions.csv file done\n",
      "KAUN BANEGA CROREPATI 3-Mentions.csv file done\n",
      "MAIN MAIKE CHALI JAUNGI-Mentions.csv file done\n",
      "MAYAVI MALING-Mentions.csv file done\n",
      "PAPA BY CHANCE-Mentions.csv file done\n",
      "RADHAKRISHN-Mentions.csv file done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-124350399928>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzee\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msm_pd_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mdt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "news_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "blogs_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "tumbler_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "instagram_ln=['No','Source','Link','Date(ET)','Time(ET)','Author ID','Author Name','Language','Location','Contents','HashTags','Likes','Comments','Attachments','Brand Images','Object Images','Food Images','Scene Images','Selfie','Sentiment','Themes','Classifications','Entities','Unique ID']\n",
    "twitter_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "forum_ln=['No','Source','Host','Link','Date(ET)','Time(ET)','LocalTime','Category','Author ID','Author Name','Author URL','Authority','Followers','Following','Age','Gender','Language','Country','Province/State','City','Location','Sentiment','Themes','Classifications','Entities','Alexa Rank','Alexa Reach','Title','Snippet','Contents','Summary','Bio','Unique ID','Post Source']\n",
    "sm_dict={'NEWS':news_ln,\n",
    "        'TUMBLR':tumbler_ln,\n",
    "        'BLOGS':blogs_ln,\n",
    "        'INSTAGRAM':instagram_ln,\n",
    "        'TWITTER':twitter_ln,\n",
    "        'FORUMS':forum_ln}\n",
    "sm_pd_dict={'NEWS':pd.DataFrame(),\n",
    "        'TUMBLR':pd.DataFrame(),\n",
    "        'BLOGS':pd.DataFrame(),\n",
    "        'INSTAGRAM':pd.DataFrame(),\n",
    "        'TWITTER':pd.DataFrame(),\n",
    "        'FORUMS':pd.DataFrame()}\n",
    "bad_files=list()\n",
    "k=0\n",
    "for dr in ldr:\n",
    "    while os.path.isdir(dr):\n",
    "        os.chdir(os.path.join(zee,dr))\n",
    "        lst=os.listdir()\n",
    "        for fle in lst:\n",
    "            if k>1e10:\n",
    "                break\n",
    "            k+=1\n",
    "            try:\n",
    "                data=pd.read_csv(fle,skiprows=13,header=None,error_bad_lines=False,dtype=str)\n",
    "                for kys in sm_dict.keys():\n",
    "                    news=data[data[1]==kys]\n",
    "                    news=news.iloc[:,:len(sm_dict[kys])]\n",
    "                    news.columns=sm_dict[kys]\n",
    "                    sname=fle.split(\".\")[0]\n",
    "                    pattern=re.compile(r\"(\\d|\\s)\")\n",
    "                    nname=pattern.sub(\"\",sname)\n",
    "                    news['showname']=sname\n",
    "                    news['nname']=nname\n",
    "                    news['Date(ET)']=pd.to_datetime(news['Date(ET)']+' '+news['Time(ET)'])\n",
    "                    sm_pd_dict[kys]=pd.concat([sm_pd_dict[kys],news],axis=0)\n",
    "                    del news\n",
    "                gc.collect()\n",
    "                print(\"{} file done\".format(fle))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                bad_files.append(fle)\n",
    "                print(\"{} issue in this file-------------------------------------------------\".format(fle))\n",
    "#                 traceback.print_exc()\n",
    "                continue\n",
    "    os.chdir(zee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in sm_pd_dict.values():\n",
    "    dt.dropna(axis='columns',how='all',inplace=True)\n",
    "    dt.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1097031 entries, 0 to 1097030\n",
      "Data columns (total 31 columns):\n",
      "No                 1097031 non-null object\n",
      "Source             1097031 non-null object\n",
      "Host               1097031 non-null object\n",
      "Link               1097031 non-null object\n",
      "Date(ET)           1097031 non-null datetime64[ns]\n",
      "Time(ET)           1097031 non-null object\n",
      "LocalTime          1097031 non-null object\n",
      "Author ID          1096896 non-null object\n",
      "Author Name        1096705 non-null object\n",
      "Author URL         1096896 non-null object\n",
      "Authority          1096896 non-null object\n",
      "Followers          1096896 non-null object\n",
      "Following          1096896 non-null object\n",
      "Gender             760372 non-null object\n",
      "Language           1097031 non-null object\n",
      "Country            648249 non-null object\n",
      "Province/State     332377 non-null object\n",
      "City               327449 non-null object\n",
      "Location           855316 non-null object\n",
      "Sentiment          1097031 non-null object\n",
      "Themes             570981 non-null object\n",
      "Classifications    631262 non-null object\n",
      "Entities           631275 non-null object\n",
      "Snippet            1097031 non-null object\n",
      "Contents           1097031 non-null object\n",
      "Summary            936306 non-null object\n",
      "Bio                917451 non-null object\n",
      "Unique ID          1097031 non-null object\n",
      "Post Source        1097031 non-null object\n",
      "showname           1097031 non-null object\n",
      "nname              1097031 non-null object\n",
      "dtypes: datetime64[ns](1), object(30)\n",
      "memory usage: 259.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sm_pd_dict['TWITTER'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sm_data','wb') as sm:\n",
    "    pickle.dump(sm_pd_dict,sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter=sm_pd_dict['TWITTER'].copy()\n",
    "twitter.Contents=twitter.Contents.str.lower()\n",
    "twitter['original']=~twitter.Contents.str.startswith(('rt','qt'))\n",
    "cnt_unique=twitter[twitter.original].groupby('nname')['Unique ID'].nunique().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings=pd.read_csv(\"ratings.csv\")\n",
    "# ratings.groupby('Showname').max().to_csv(\"max_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=pd.read_csv(\"max_ratings.csv\")\n",
    "train,test=train_test_split(ratings,test_size=0.3,random_state=211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 46), (24, 46))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Showname</th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "      <th>W3</th>\n",
       "      <th>W4</th>\n",
       "      <th>W5</th>\n",
       "      <th>W6</th>\n",
       "      <th>W7</th>\n",
       "      <th>W8</th>\n",
       "      <th>W9</th>\n",
       "      <th>W10</th>\n",
       "      <th>W11</th>\n",
       "      <th>W12</th>\n",
       "      <th>W13</th>\n",
       "      <th>W14</th>\n",
       "      <th>W15</th>\n",
       "      <th>W16</th>\n",
       "      <th>W17</th>\n",
       "      <th>W18</th>\n",
       "      <th>W19</th>\n",
       "      <th>W20</th>\n",
       "      <th>W21</th>\n",
       "      <th>W22</th>\n",
       "      <th>W23</th>\n",
       "      <th>W24</th>\n",
       "      <th>W25</th>\n",
       "      <th>W26</th>\n",
       "      <th>W27</th>\n",
       "      <th>W28</th>\n",
       "      <th>W29</th>\n",
       "      <th>W30</th>\n",
       "      <th>W31</th>\n",
       "      <th>W32</th>\n",
       "      <th>W33</th>\n",
       "      <th>W34</th>\n",
       "      <th>W35</th>\n",
       "      <th>W36</th>\n",
       "      <th>W37</th>\n",
       "      <th>W38</th>\n",
       "      <th>W39</th>\n",
       "      <th>W40</th>\n",
       "      <th>W41</th>\n",
       "      <th>W42</th>\n",
       "      <th>W43</th>\n",
       "      <th>W44</th>\n",
       "      <th>W45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEVONKEDEVMAHADEV-Mentions</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>zeetv-shows-sa-re-ga-ma-pa-Mentions</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sonytv-show-prithvi-vallabh-Mentions</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALADDINNAAMTOHSUNAHOGA-Mentions</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEECHWALEBAPUDEKHRAHAHAI-Mentions</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Showname    W1    W2    W3    W4    W5    W6  \\\n",
       "5             DEVONKEDEVMAHADEV-Mentions  0.71  0.75  0.71  0.62  0.73  0.66   \n",
       "78   zeetv-shows-sa-re-ga-ma-pa-Mentions  1.17  0.97  1.06  0.81   NaN   NaN   \n",
       "59  sonytv-show-prithvi-vallabh-Mentions  0.95  0.73  0.74  0.66  0.60  0.63   \n",
       "0        ALADDINNAAMTOHSUNAHOGA-Mentions  1.99  2.29  1.96  1.80  1.63  1.55   \n",
       "1      BEECHWALEBAPUDEKHRAHAHAI-Mentions  0.53  0.39  0.37  0.42  0.39  0.34   \n",
       "\n",
       "      W7    W8    W9   W10   W11   W12   W13   W14   W15   W16   W17   W18  \\\n",
       "5   0.65  0.50  0.73  1.08  0.93  0.78  0.77  0.58   NaN   NaN   NaN   NaN   \n",
       "78   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "59  0.56  0.56  0.45  0.32  0.27  0.27  0.28  0.31  0.33  0.29  0.27  0.29   \n",
       "0   1.58  1.27  1.24  1.23  1.13  0.94   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "     W19   W20   W21  W22  W23  W24  W25  W26  W27  W28  W29  W30  W31  W32  \\\n",
       "5    NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "78   NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "59  0.31  0.29  0.23  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "0    NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1    NaN   NaN   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "    W33  W34  W35  W36  W37  W38  W39  W40  W41  W42  W43  W44  W45  \n",
       "5   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "78  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "59  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "0   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_handle=[\"http://twitter.com/AndTVOfficial/\",\"http://twitter.com/ColorsTV/\",\"http://twitter.com/SonySABTV/\",\"http://twitter.com/SonyTV/\",\"http://twitter.com/StarPlus/\",\"http://twitter.com/ZeeTV/\"]\n",
    "def get_data_by_days(shows):\n",
    "    a=shows.Link.str.contains(r'(http://twitter.com/AndTVOfficial/|http://twitter.com/ColorsTV/|http://twitter.com/SonySABTV/|http://twitter.com/SonyTV/|http://twitter.com/StarPlus/|http://twitter.com/ZeeTV/)',regex=True)\n",
    "    twitter=shows[~a].copy()\n",
    "    twitter.reset_index(drop=True,inplace=True)\n",
    "    twitter['clean_content']=twitter.Contents.str.replace(r\"http.*[\\s\\n]\",\"\")\n",
    "    dt_min=twitter.groupby('nname')['Date(ET)'].min().to_frame().reset_index()\n",
    "    dt_min['0_7_date']=dt_min['Date(ET)'].apply(lambda x: x + dt.timedelta(days=7))\n",
    "    dt_min['7_14_date']=dt_min['Date(ET)'].apply(lambda x: x + dt.timedelta(days=14))\n",
    "    dt_min['14_21_date']=dt_min['Date(ET)'].apply(lambda x: x + dt.timedelta(days=21))\n",
    "    dt_min['max_dt']=dt_min['Date(ET)'].apply(lambda x: x + dt.timedelta(days=30))\n",
    "    twitter2=twitter.merge(dt_min.drop('Date(ET)',axis=1),on='nname',how='left')\n",
    "    twitter2=twitter2[twitter2['Date(ET)']<=twitter2.max_dt].copy()\n",
    "    print(twitter2.groupby('nname')['Date(ET)'].apply(lambda x:max(x)-min(x)))\n",
    "    return twitter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "S:\\Anaconda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning:\n",
      "\n",
      "This pattern has match groups. To actually get the groups, use str.extract.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nname\n",
      "ALADDINNAAMTOHSUNAHOGA-Mentions                            29 days 23:51:32\n",
      "BEECHWALEBAPUDEKHRAHAHAI-Mentions                          28 days 14:52:01\n",
      "BIGGBOSS-Mentions                                          29 days 23:59:53\n",
      "CHANDRASHEKAR-Mentions                                     29 days 22:11:20\n",
      "COMEDYCIRCUS-Mentions                                      29 days 23:40:50\n",
      "DILHITOHAI-Mentions                                        29 days 23:34:05\n",
      "DetectiveDidi-Mentions                                     29 days 19:47:54\n",
      "ENTERTAINMENTKIRAAT-Mentions                               29 days 23:27:45\n",
      "Guddan-Mentions                                            27 days 22:06:14\n",
      "HARSHAAKHPEULLUBAITHAAHAI-Mentions                         29 days 05:37:18\n",
      "INDIAKEMASTKALANDAR-Mentions                               29 days 23:06:02\n",
      "IndiasGotTalent-Mentions                                   29 days 23:24:39\n",
      "JIJAJICHHATPARHAIN-Mentions                                29 days 23:50:55\n",
      "JIODHANDHANADHANLIVE-Mentions                              29 days 23:58:24\n",
      "KAUNBANEGACROREPATI-Mentions                               29 days 23:50:53\n",
      "KHICHDI-Mentions                                           29 days 11:43:19\n",
      "KRISHNACHALILONDON-Mentions                                29 days 23:22:30\n",
      "MAINMAIKECHALIJAUNGI-Mentions                              29 days 23:44:09\n",
      "MAYAVIMALING-Mentions                                      29 days 15:34:44\n",
      "NAZAR-Mentions                                             29 days 22:51:26\n",
      "PAPABYCHANCE-Mentions                                      29 days 16:49:22\n",
      "RADHAKRISHN-Mentions                                       29 days 23:55:17\n",
      "THEVOICEINDIAKIDS-Mentions                                 29 days 23:17:38\n",
      "andtv-show-perfect-pati-Mentions                           29 days 08:29:51\n",
      "andtvofficial-show-bitti-businesswali-Mentions             28 days 03:09:36\n",
      "andtvofficial-show-high-fever-Mentions                     29 days 23:19:07\n",
      "andtvofficial-show-laal-ishq-Mentions                      29 days 14:19:37\n",
      "andtvofficial-show-love-me-india-Mentions                  29 days 23:56:13\n",
      "andtvofficial-show-mitegi-lakshmanrekha-Mentions           29 days 23:45:25\n",
      "andtvofficial-show-vikram-betaal-Mentions                  29 days 23:11:38\n",
      "                                                                 ...       \n",
      "colorstv-show-savitri-devi-college-and-hospital-Mentions   28 days 02:19:16\n",
      "colorstv-show-silsila-badalte-rishton-ka-Mentions          29 days 17:18:01\n",
      "sony-tv--show---cid-Mentions                               29 days 23:50:47\n",
      "sony-tv-show-dus-ka-dum-Mentions                           29 days 23:59:53\n",
      "sony-tv-show-indian-idol-Mentions                          30 days 00:00:00\n",
      "sonysab-show-namune-Mentions                               29 days 17:09:34\n",
      "sonysab-show-saat-phero-ki-hera-pherie-Mentions            29 days 23:55:54\n",
      "sonysab-show-shriman-shrimati-phir-se-Mentions             27 days 07:32:25\n",
      "sonysab-show-supersister-Mentions                          28 days 07:17:48\n",
      "sonytv-show-crime-patrol-Mentions                          29 days 23:06:53\n",
      "sonytv-show-prithvi-vallabh-Mentions                       29 days 23:59:13\n",
      "sonytv-show-zindagikecrossroads-Mentions                   29 days 23:37:54\n",
      "sonytv-shows-yeh-pyaar-nahi-tho-kya-hai-Mentions           29 days 23:49:57\n",
      "star-plus-show-danceplus-Mentions                          29 days 23:42:35\n",
      "star-plus-show-dil-hai-hindustani--Mentions                29 days 23:36:05\n",
      "starplus-show-kasautii-zindagi-kay-Mentions                 1 days 00:47:42\n",
      "starplus-show-kulfi-kumar-bajewala-Mentions                28 days 08:25:40\n",
      "starplus-show-mariam-khan-reporting-live-Mentions          29 days 21:27:06\n",
      "starplus-show-qayamat-ki-raat-Mentions                     29 days 22:20:33\n",
      "starplus-show-sabse-smart-kaun-Mentions                    29 days 22:12:55\n",
      "zee-tv---show---ishq-subhan-allah-Mentions                 29 days 23:58:51\n",
      "zee-tv---show---juzzbaaat-Mentions                         29 days 23:57:42\n",
      "zee-tv-shows-fear-files-Mentions                           29 days 12:16:21\n",
      "zeetv---show---kaleerein-Mentions                          29 days 20:47:57\n",
      "zeetv-show-aap-ke-aa-jane-se-Mentions                      29 days 15:13:01\n",
      "zeetv-show-did-lil-masters-Mentions                        29 days 21:41:59\n",
      "zeetv-show-ye-teri-galiyan-Mentions                        29 days 03:51:04\n",
      "zeetv-shows-india-best-dramebaaz-Mentions                  29 days 22:11:36\n",
      "zeetv-shows-maggie-kitchen-journeys-Mentions                8 days 22:42:40\n",
      "zeetv-shows-sa-re-ga-ma-pa-Mentions                        29 days 23:55:39\n",
      "Name: Date(ET), Length: 71, dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "twitter2=get_data_by_days(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                 251\n",
       "Source             251\n",
       "Host               251\n",
       "Link               251\n",
       "Date(ET)           251\n",
       "Time(ET)           251\n",
       "LocalTime          251\n",
       "Author ID          251\n",
       "Author Name        251\n",
       "Author URL         251\n",
       "Authority          251\n",
       "Followers          251\n",
       "Following          251\n",
       "Gender             137\n",
       "Language           251\n",
       "Country            157\n",
       "Province/State      91\n",
       "City                90\n",
       "Location           193\n",
       "Sentiment          251\n",
       "Themes               9\n",
       "Classifications      9\n",
       "Entities             9\n",
       "Snippet            251\n",
       "Contents           251\n",
       "Summary            223\n",
       "Bio                211\n",
       "Unique ID          251\n",
       "Post Source        251\n",
       "showname           251\n",
       "nname              251\n",
       "original           251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter[twitter.nname==\"starplus-show-kulfi-kumar-bajewala-Mentions\"].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
